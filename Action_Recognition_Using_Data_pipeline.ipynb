{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95846bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries.\n",
    "!pip install pafy moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c57d8",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22724e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the UCF50 Dataset\n",
    "!wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar\n",
    "\n",
    "#Extract the Dataset\n",
    "!unrar x UCF50.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Matplotlib figure and specify the size of the figure.\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "# Get the names of all classes/categories in UCF50.\n",
    "all_classes_names = os.listdir('UCF50')\n",
    "\n",
    "# Generate a list of 20 random values. The values will be between 0-50,\n",
    "# where 50 is the total number of class in the dataset.\n",
    "random_range = random.sample(range(len(all_classes_names)), 20)\n",
    "\n",
    "# Iterating through all the generated random values.\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    "\n",
    "    # Retrieve a Class Name using the Random Index.\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    "\n",
    "    # Retrieve the list of all the video files present in the randomly selected Class Directory.\n",
    "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
    "\n",
    "    # Randomly select a video file from the list retrieved from the randomly selected Class Directory.\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "\n",
    "    # Initialize a VideoCapture object to read from the video File.\n",
    "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
    "\n",
    "    # Read the first frame of the video file.\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    # Release the VideoCapture object.\n",
    "    video_reader.release()\n",
    "\n",
    "    # Convert the frame from BGR into RGB format.\n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Write the class name on the video frame.\n",
    "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the frame.\n",
    "    plt.subplot(5, 4, counter);plt.imshow(rgb_frame);plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c11754",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the target dimensions for preprocessing video frames\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "\n",
    "# Define how many consecutive frames from each video will be used as input to create temporal sequences\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "# Set the path to the root directory where the UCF50 action recognition dataset is stored\n",
    "DATASET_DIR = \"UCF50\"\n",
    "\n",
    "# Build a list of action class names for model training - using the first 20 classes from the dataset for quicker training\n",
    "CLASSES_LIST = []\n",
    "for i in range(10):\n",
    "  CLASSES_LIST.append(all_classes_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to dataset\n",
    "DATASET_DIR = \"UCF50\"\n",
    "\n",
    "# Automatically get class names from folder names\n",
    "CLASSES_LIST = sorted(CLASSES_LIST)\n",
    "\n",
    "print(\"Classes found:\", CLASSES_LIST)\n",
    "print(\"Total classes:\", len(CLASSES_LIST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6e015",
   "metadata": {},
   "source": [
    "## SetUp Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ae5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ to extract frames ------------------\n",
    "def extract_video_frames(video_path):\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "        success, frame = video_reader.read()\n",
    "        if not success:\n",
    "            break\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    return frames_list\n",
    "\n",
    "\n",
    "# ------------------ Build list of video paths + labels ------------------\n",
    "video_paths, labels = [], []\n",
    "\n",
    "for class_idx, class_name in enumerate(CLASSES_LIST):\n",
    "    class_dir = os.path.join(DATASET_DIR, class_name)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        video_paths.append(os.path.join(class_dir, file_name))\n",
    "        labels.append(class_idx)\n",
    "\n",
    "labels = to_categorical(labels, num_classes=len(CLASSES_LIST))\n",
    "\n",
    "# Train-test split\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    video_paths, labels, test_size=0.2, random_state=seed_constant, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_paths)}, Testing samples: {len(test_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_generator(video_paths, labels):\n",
    "    def gen():\n",
    "        for path, label in zip(video_paths, labels):\n",
    "            frames = extract_video_frames(path)\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                yield np.array(frames, dtype=np.float32), label\n",
    "    return gen\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    video_generator(train_paths, train_labels),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(len(CLASSES_LIST),), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    video_generator(test_paths, test_labels),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(len(CLASSES_LIST),), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ee618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle, batch, prefetch\n",
    "BATCH_SIZE = 4\n",
    "train_dataset = train_dataset.shuffle(100).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19030f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import ConvLSTM2D, MaxPooling3D, TimeDistributed, Dense, Flatten, Dropout\n",
    "\n",
    "# ------------------ ConvLSTM Model ------------------\n",
    "def build_convlstm_network():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh',\n",
    "                         recurrent_dropout=0.2, return_sequences=True,\n",
    "                         input_shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh',\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters=14, kernel_size=(3, 3), activation='tanh',\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), activation='tanh',\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len(CLASSES_LIST), activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_convlstm_network()\n",
    "model.summary()\n",
    "\n",
    "# ------------------ Compile & Train ------------------\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Create an Instance of Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    callbacks = [early_stopping_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
